# ResultValidator (US5) - è®¾è®¡æ–¹æ¡ˆ

**åˆ›å»ºæ—¥æœŸ**: 2026-01-30  
**çŠ¶æ€**: å¾…å®ç°  
**ä¼˜å…ˆçº§**: P3 (å¯é€‰å¢å¼ºåŠŸèƒ½)

---

## ğŸ“‹ æ¦‚è¿°

**ç›®æ ‡**: éªŒè¯æŸ¥è¯¢ç»“æœçš„è´¨é‡å’Œç›¸å…³æ€§ï¼Œåœ¨è¿”å›ç»™ç”¨æˆ·å‰æ£€æµ‹å¹¶å¤„ç†å¸¸è§é—®é¢˜ã€‚

**ä»·å€¼**: 
- æå‡ç”¨æˆ·ä½“éªŒï¼ˆå‡å°‘ç©ºç»“æœå’Œè¯¯åŒ¹é…ï¼‰
- å¢å¼ºç³»ç»Ÿæ™ºèƒ½ï¼ˆAI éªŒè¯ç»“æœè¯­ä¹‰åŒ¹é…ï¼‰
- æä¾›æŸ¥è¯¢æ”¹è¿›å»ºè®®

**èŒƒå›´**: å¯é€‰åŠŸèƒ½ï¼Œä¸å½±å“æ ¸å¿ƒ MVP

---

## ğŸ¯ ç”¨æˆ·æ•…äº‹ (US5)

### éªŒæ”¶åœºæ™¯

1. **ç»™å®š** ç”Ÿæˆçš„ SQL æŸ¥è¯¢ï¼Œ**å½“** ç³»ç»Ÿæµ‹è¯•æ‰§è¡Œï¼Œ**é‚£ä¹ˆ** æŸ¥è¯¢æˆåŠŸè¿è¡Œå¹¶è¿”å›ç»“æœæˆ–é€‚å½“çš„é”™è¯¯æ¶ˆæ¯

2. **ç»™å®š** æŸ¥è¯¢ç»“æœå’ŒåŸå§‹è‡ªç„¶è¯­è¨€è¯·æ±‚ï¼Œ**å½“** ç³»ç»ŸéªŒè¯ç›¸å…³æ€§ï¼Œ**é‚£ä¹ˆ** AI æ¨¡å‹ç¡®è®¤ç»“æœä¸ç”¨æˆ·æ„å›¾åŒ¹é…æˆ–å»ºè®®æŸ¥è¯¢æ”¹è¿›

3. **ç»™å®š** è¿”å›æ„å¤–ç©ºç»“æœçš„æŸ¥è¯¢ï¼Œ**å½“** éªŒè¯å‘ç”Ÿï¼Œ**é‚£ä¹ˆ** ç³»ç»Ÿå»ºè®®æ›¿ä»£æŸ¥è¯¢æˆ–è¯·æ±‚æ¾„æ¸…

4. **ç»™å®š** æœ‰è¯­æ³•é”™è¯¯çš„æŸ¥è¯¢ï¼Œ**å½“** ç³»ç»Ÿæµ‹è¯•æ‰§è¡Œï¼Œ**é‚£ä¹ˆ** åœ¨è¿”å›ç»™ç”¨æˆ·ä¹‹å‰æ•è·é”™è¯¯ï¼Œå¹¶ä¸”ç³»ç»Ÿå°è¯•ä¿®å¤æˆ–é‡æ–°ç”ŸæˆæŸ¥è¯¢

---

## ğŸ“ è®¾è®¡æ–¹æ¡ˆ

### æ ¸å¿ƒåŠŸèƒ½

ResultValidator æä¾› **ä¸¤å±‚éªŒè¯**ï¼š

#### **Level 1: åŸºç¡€éªŒè¯ (æœ¬åœ°)** âœ… å¿«é€Ÿã€æ—  AI è°ƒç”¨
- âœ… ç©ºç»“æœæ£€æµ‹
- âœ… ç»“æœæ•°é‡å¼‚å¸¸æ£€æµ‹ï¼ˆè¿‡å°‘/è¿‡å¤šï¼‰
- âœ… åˆ—ååŒ¹é…åº¦æ£€æŸ¥
- âœ… æ•°æ®ç±»å‹ä¸€è‡´æ€§éªŒè¯

#### **Level 2: è¯­ä¹‰éªŒè¯ (AI)** ğŸ¤– å¯é€‰ã€éœ€è¦ OpenAI API
- ğŸ¤– AI éªŒè¯ç»“æœä¸ç”¨æˆ·æ„å›¾åŒ¹é…åº¦
- ğŸ¤– ç”ŸæˆæŸ¥è¯¢æ”¹è¿›å»ºè®®
- ğŸ¤– æä¾›æ›¿ä»£æŸ¥è¯¢æ–¹æ¡ˆ

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ•°æ®æ¨¡å‹ (æ–°å¢)

```python
# src/postgres_mcp/models/validation.py

from enum import Enum
from pydantic import BaseModel, Field

class ValidationLevel(str, Enum):
    """éªŒè¯çº§åˆ«"""
    BASIC = "basic"          # ä»…åŸºç¡€éªŒè¯
    SEMANTIC = "semantic"    # åŒ…å« AI è¯­ä¹‰éªŒè¯

class ValidationIssue(str, Enum):
    """éªŒè¯é—®é¢˜ç±»å‹"""
    EMPTY_RESULT = "empty_result"              # ç©ºç»“æœ
    TOO_FEW_ROWS = "too_few_rows"              # ç»“æœè¿‡å°‘
    TOO_MANY_ROWS = "too_many_rows"            # ç»“æœè¿‡å¤šï¼ˆå¯èƒ½éœ€è¦æ›´ç²¾ç¡®çš„æŸ¥è¯¢ï¼‰
    COLUMN_MISMATCH = "column_mismatch"        # åˆ—åä¸é¢„æœŸä¸ç¬¦
    TYPE_MISMATCH = "type_mismatch"            # æ•°æ®ç±»å‹ä¸ä¸€è‡´
    SEMANTIC_MISMATCH = "semantic_mismatch"    # AI æ£€æµ‹åˆ°è¯­ä¹‰ä¸åŒ¹é…

class ValidationSuggestion(BaseModel):
    """éªŒè¯æ”¹è¿›å»ºè®®"""
    issue: ValidationIssue
    message: str                               # é—®é¢˜æè¿°
    suggested_query: str | None = None         # å»ºè®®çš„æ›¿ä»£æŸ¥è¯¢
    confidence: float = Field(ge=0.0, le=1.0)  # å»ºè®®ç½®ä¿¡åº¦

class ValidationResult(BaseModel):
    """éªŒè¯ç»“æœ"""
    valid: bool                                # æ˜¯å¦é€šè¿‡éªŒè¯
    issues: list[ValidationIssue] = Field(default_factory=list)
    suggestions: list[ValidationSuggestion] = Field(default_factory=list)
    semantic_match_score: float | None = None  # AI è¯­ä¹‰åŒ¹é…åˆ†æ•° (0-1)
    details: dict[str, object] = Field(default_factory=dict)  # è¯¦ç»†ä¿¡æ¯
```

---

### æ ¸å¿ƒç»„ä»¶

#### 1. ResultValidator (ä¸»éªŒè¯å™¨)

```python
# src/postgres_mcp/core/result_validator.py

from __future__ import annotations
from typing import TYPE_CHECKING

import structlog

from postgres_mcp.models.result import QueryResult
from postgres_mcp.models.validation import (
    ValidationIssue,
    ValidationLevel,
    ValidationResult,
    ValidationSuggestion,
)

if TYPE_CHECKING:
    from postgres_mcp.ai.openai_client import OpenAIClient

logger = structlog.get_logger(__name__)


class ResultValidator:
    """
    éªŒè¯æŸ¥è¯¢ç»“æœè´¨é‡å’Œç›¸å…³æ€§.
    
    æä¾›ä¸¤å±‚éªŒè¯:
    - Level 1: åŸºç¡€éªŒè¯ (æœ¬åœ°, å¿«é€Ÿ)
    - Level 2: AI è¯­ä¹‰éªŒè¯ (å¯é€‰, éœ€è¦ OpenAI)
    """
    
    def __init__(
        self,
        openai_client: OpenAIClient | None = None,
        min_expected_rows: int = 1,          # æœ€å°‘é¢„æœŸè¡Œæ•°
        max_expected_rows: int = 10000,      # æœ€å¤§åˆç†è¡Œæ•°
        semantic_threshold: float = 0.7,     # AI è¯­ä¹‰åŒ¹é…é˜ˆå€¼
    ) -> None:
        self._openai_client = openai_client
        self._min_expected_rows = min_expected_rows
        self._max_expected_rows = max_expected_rows
        self._semantic_threshold = semantic_threshold
    
    async def validate(
        self,
        result: QueryResult,
        natural_language: str,
        level: ValidationLevel = ValidationLevel.BASIC,
    ) -> ValidationResult:
        """
        éªŒè¯æŸ¥è¯¢ç»“æœ.
        
        Args:
            result: æŸ¥è¯¢ç»“æœ
            natural_language: åŸå§‹è‡ªç„¶è¯­è¨€æŸ¥è¯¢
            level: éªŒè¯çº§åˆ« (basic/semantic)
        
        Returns:
            ValidationResult åŒ…å«é—®é¢˜å’Œå»ºè®®
        """
        # Step 1: åŸºç¡€éªŒè¯ (æ€»æ˜¯æ‰§è¡Œ)
        validation = await self._basic_validation(result, natural_language)
        
        # Step 2: è¯­ä¹‰éªŒè¯ (å¯é€‰)
        if level == ValidationLevel.SEMANTIC and self._openai_client:
            semantic_validation = await self._semantic_validation(
                result, natural_language
            )
            validation = self._merge_validations(validation, semantic_validation)
        
        logger.info(
            "result_validation_complete",
            valid=validation.valid,
            issues=len(validation.issues),
            level=level.value,
        )
        
        return validation
    
    async def _basic_validation(
        self, result: QueryResult, natural_language: str
    ) -> ValidationResult:
        """åŸºç¡€éªŒè¯ (æœ¬åœ°, æ—  AI è°ƒç”¨)"""
        issues: list[ValidationIssue] = []
        suggestions: list[ValidationSuggestion] = []
        
        # æ£€æŸ¥ 1: ç©ºç»“æœ
        if result.row_count == 0:
            issues.append(ValidationIssue.EMPTY_RESULT)
            suggestions.append(
                ValidationSuggestion(
                    issue=ValidationIssue.EMPTY_RESULT,
                    message=(
                        "æŸ¥è¯¢è¿”å›ç©ºç»“æœã€‚å¯èƒ½åŸå› : "
                        "1) æ•°æ®åº“ä¸­æ²¡æœ‰åŒ¹é…çš„æ•°æ® "
                        "2) è¿‡æ»¤æ¡ä»¶è¿‡äºä¸¥æ ¼ "
                        "3) è¡¨åæˆ–åˆ—åé”™è¯¯"
                    ),
                    confidence=0.8,
                )
            )
        
        # æ£€æŸ¥ 2: ç»“æœè¿‡å°‘ (å¯èƒ½æŸ¥è¯¢è¿‡äºä¸¥æ ¼)
        elif result.row_count < self._min_expected_rows:
            issues.append(ValidationIssue.TOO_FEW_ROWS)
            suggestions.append(
                ValidationSuggestion(
                    issue=ValidationIssue.TOO_FEW_ROWS,
                    message=f"ä»…è¿”å› {result.row_count} è¡Œç»“æœã€‚è€ƒè™‘æ”¾å®½è¿‡æ»¤æ¡ä»¶ã€‚",
                    confidence=0.6,
                )
            )
        
        # æ£€æŸ¥ 3: ç»“æœè¿‡å¤š (å¯èƒ½éœ€è¦æ›´ç²¾ç¡®çš„æŸ¥è¯¢)
        elif result.row_count >= self._max_expected_rows or result.truncated:
            issues.append(ValidationIssue.TOO_MANY_ROWS)
            suggestions.append(
                ValidationSuggestion(
                    issue=ValidationIssue.TOO_MANY_ROWS,
                    message=(
                        f"è¿”å›å¤§é‡ç»“æœ ({result.row_count} è¡Œ)ã€‚"
                        "è€ƒè™‘æ·»åŠ æ›´å…·ä½“çš„è¿‡æ»¤æ¡ä»¶æˆ–é™åˆ¶è¿”å›è¡Œæ•°ã€‚"
                    ),
                    confidence=0.7,
                )
            )
        
        # æ£€æŸ¥ 4: åˆ—ååŒ¹é…åº¦ (ç®€å•å…³é”®è¯æ£€æŸ¥)
        # æå–è‡ªç„¶è¯­è¨€ä¸­çš„å…³é”®è¯ï¼Œæ£€æŸ¥æ˜¯å¦å‡ºç°åœ¨åˆ—åä¸­
        nl_keywords = self._extract_keywords(natural_language)
        column_names = {col.name.lower() for col in result.columns}
        
        matched_keywords = sum(1 for kw in nl_keywords if kw in column_names)
        if nl_keywords and matched_keywords == 0:
            issues.append(ValidationIssue.COLUMN_MISMATCH)
            suggestions.append(
                ValidationSuggestion(
                    issue=ValidationIssue.COLUMN_MISMATCH,
                    message=(
                        f"æŸ¥è¯¢å…³é”®è¯ ({', '.join(nl_keywords)}) "
                        f"æœªåœ¨ç»“æœåˆ—åä¸­å‡ºç° ({', '.join(column_names)})ã€‚"
                        "å¯èƒ½æŸ¥è¯¢çš„è¡¨æˆ–åˆ—ä¸æ­£ç¡®ã€‚"
                    ),
                    confidence=0.5,
                )
            )
        
        # éªŒè¯é€šè¿‡æ¡ä»¶: æ— ä¸¥é‡é—®é¢˜
        valid = ValidationIssue.EMPTY_RESULT not in issues
        
        return ValidationResult(
            valid=valid,
            issues=issues,
            suggestions=suggestions,
            details={
                "row_count": result.row_count,
                "column_count": len(result.columns),
                "truncated": result.truncated,
            },
        )
    
    async def _semantic_validation(
        self, result: QueryResult, natural_language: str
    ) -> ValidationResult:
        """AI è¯­ä¹‰éªŒè¯ (éœ€è¦ OpenAI)"""
        if not self._openai_client:
            return ValidationResult(valid=True)
        
        try:
            # æ„å»ºéªŒè¯ prompt
            prompt = self._build_validation_prompt(result, natural_language)
            
            # è°ƒç”¨ AI éªŒè¯
            ai_response = await self._openai_client.validate_result_relevance(
                natural_language=natural_language,
                sql=result.sql or "",
                columns=[col.name for col in result.columns],
                sample_rows=result.rows[:5],  # åªå‘é€å‰ 5 è¡Œä½œä¸ºæ ·æœ¬
            )
            
            # è§£æ AI å“åº”
            match_score = ai_response.get("match_score", 1.0)
            is_relevant = ai_response.get("is_relevant", True)
            ai_suggestion = ai_response.get("suggestion")
            
            issues = []
            suggestions = []
            
            if match_score < self._semantic_threshold:
                issues.append(ValidationIssue.SEMANTIC_MISMATCH)
                suggestions.append(
                    ValidationSuggestion(
                        issue=ValidationIssue.SEMANTIC_MISMATCH,
                        message=(
                            f"AI æ£€æµ‹åˆ°æŸ¥è¯¢ç»“æœä¸ç”¨æˆ·æ„å›¾åŒ¹é…åº¦è¾ƒä½ "
                            f"(å¾—åˆ†: {match_score:.2f})ã€‚"
                        ),
                        suggested_query=ai_suggestion,
                        confidence=match_score,
                    )
                )
            
            return ValidationResult(
                valid=is_relevant,
                issues=issues,
                suggestions=suggestions,
                semantic_match_score=match_score,
            )
        
        except Exception as e:
            logger.warning("semantic_validation_failed", error=str(e))
            # AI éªŒè¯å¤±è´¥ä¸åº”é˜»æ­¢æŸ¥è¯¢ï¼Œè¿”å›é€šè¿‡
            return ValidationResult(valid=True)
    
    def _extract_keywords(self, text: str) -> list[str]:
        """ä»è‡ªç„¶è¯­è¨€ä¸­æå–å…³é”®è¯"""
        # ç®€å•å®ç°: æå–é•¿åº¦ > 3 çš„å•è¯ï¼Œæ’é™¤å¸¸è§åœç”¨è¯
        stopwords = {
            "æ˜¾ç¤º", "æŸ¥çœ‹", "åˆ—å‡º", "æ‰€æœ‰", "æŸ¥è¯¢", "è·å–",
            "show", "list", "get", "all", "select", "from",
            "where", "the", "and", "or",
        }
        words = text.lower().split()
        return [w for w in words if len(w) > 3 and w not in stopwords]
    
    def _merge_validations(
        self, basic: ValidationResult, semantic: ValidationResult
    ) -> ValidationResult:
        """åˆå¹¶åŸºç¡€éªŒè¯å’Œè¯­ä¹‰éªŒè¯ç»“æœ"""
        return ValidationResult(
            valid=basic.valid and semantic.valid,
            issues=basic.issues + semantic.issues,
            suggestions=basic.suggestions + semantic.suggestions,
            semantic_match_score=semantic.semantic_match_score,
            details=basic.details,
        )
    
    def _build_validation_prompt(
        self, result: QueryResult, natural_language: str
    ) -> str:
        """æ„å»ºéªŒè¯ prompt"""
        return f"""
Given:
- User request: "{natural_language}"
- SQL executed: {result.sql}
- Columns returned: {', '.join(col.name for col in result.columns)}
- Sample rows: {result.rows[:3]}

Evaluate:
1. Does the result semantically match the user's intent?
2. If not, what query would be more appropriate?

Respond with JSON:
{{
    "is_relevant": true/false,
    "match_score": 0.0-1.0,
    "reason": "explanation",
    "suggestion": "alternative SQL query (optional)"
}}
"""
```

---

#### 2. OpenAI Client æ‰©å±• (æ–°æ–¹æ³•)

```python
# src/postgres_mcp/ai/openai_client.py

# æ·»åŠ æ–°æ–¹æ³•åˆ°ç°æœ‰çš„ OpenAIClient ç±»

async def validate_result_relevance(
    self,
    natural_language: str,
    sql: str,
    columns: list[str],
    sample_rows: list[dict[str, object]],
) -> dict[str, object]:
    """
    ä½¿ç”¨ AI éªŒè¯æŸ¥è¯¢ç»“æœä¸ç”¨æˆ·æ„å›¾çš„ç›¸å…³æ€§.
    
    Args:
        natural_language: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
        sql: æ‰§è¡Œçš„ SQL
        columns: ç»“æœåˆ—å
        sample_rows: æ ·æœ¬æ•°æ®è¡Œ
    
    Returns:
        åŒ…å« is_relevant, match_score, reason, suggestion çš„å­—å…¸
    """
    prompt = f"""
You are a database query validator. Evaluate if the SQL query result matches the user's intent.

User Request: "{natural_language}"
SQL Executed: {sql}
Result Columns: {', '.join(columns)}
Sample Data (first 3 rows): {sample_rows[:3]}

Evaluate:
1. Does the result semantically answer the user's question?
2. Are the columns relevant to the request?
3. Does the data look correct based on the sample?

Provide a match score (0.0-1.0) and explanation.
If score < 0.7, suggest an improved SQL query.

Respond ONLY with valid JSON (no markdown):
{{
    "is_relevant": true,
    "match_score": 0.95,
    "reason": "The query correctly retrieves active users as requested",
    "suggestion": null
}}
"""
    
    try:
        response = await self._client.chat.completions.create(
            model=self._model,
            messages=[
                {"role": "system", "content": "You are a database query validator."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.3,
            max_tokens=500,
            response_format={"type": "json_object"},
        )
        
        result = json.loads(response.choices[0].message.content)
        return result
    
    except Exception as e:
        logger.error("ai_validation_failed", error=str(e))
        # é»˜è®¤è®¤ä¸ºæœ‰æ•ˆï¼Œä¸é˜»æ­¢æŸ¥è¯¢
        return {
            "is_relevant": True,
            "match_score": 1.0,
            "reason": "Validation failed, assuming valid",
            "suggestion": None,
        }
```

---

#### 3. QueryExecutor é›†æˆ (å¯é€‰å¯ç”¨)

```python
# src/postgres_mcp/core/query_executor.py

# ä¿®æ”¹ __init__ æ–¹æ³•
def __init__(
    self,
    sql_generator: SQLGenerator,
    pool_manager: PoolManager,
    query_runner: QueryRunner,
    jsonl_writer: JSONLWriter | None = None,
    result_validator: ResultValidator | None = None,  # æ–°å¢: å¯é€‰
    enable_validation: bool = False,                   # æ–°å¢: é»˜è®¤å…³é—­
) -> None:
    self._sql_generator = sql_generator
    self._pool_manager = pool_manager
    self._query_runner = query_runner
    self._jsonl_writer = jsonl_writer
    self._result_validator = result_validator
    self._enable_validation = enable_validation


# ä¿®æ”¹ execute æ–¹æ³•
async def execute(
    self, 
    natural_language: str, 
    database: str, 
    limit: int = 1000,
    validate_result: bool | None = None,  # æ–°å¢: è¦†ç›–é»˜è®¤é…ç½®
) -> QueryResult:
    """Execute a natural language query and return results."""
    
    # ... ç°æœ‰çš„ SQL ç”Ÿæˆå’Œæ‰§è¡Œé€»è¾‘ ...
    
    # æŸ¥è¯¢æˆåŠŸåï¼Œæ‰§è¡Œç»“æœéªŒè¯ (å¦‚æœå¯ç”¨)
    should_validate = (
        validate_result 
        if validate_result is not None 
        else self._enable_validation
    )
    
    if should_validate and self._result_validator and result.row_count > 0:
        validation = await self._result_validator.validate(
            result=result,
            natural_language=natural_language,
            level=ValidationLevel.BASIC,  # é»˜è®¤ä»…åŸºç¡€éªŒè¯
        )
        
        # å°†éªŒè¯ç»“æœæ·»åŠ åˆ° QueryResult
        if not validation.valid:
            # å°†å»ºè®®æ·»åŠ åˆ°ç»“æœçš„ errors å­—æ®µ
            for suggestion in validation.suggestions:
                result.errors.append(
                    f"âš ï¸ {suggestion.issue.value}: {suggestion.message}"
                )
        
        logger.info(
            "result_validated",
            valid=validation.valid,
            issues=len(validation.issues),
        )
    
    return result
```

---

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### T079: å•å…ƒæµ‹è¯• ResultValidator

```python
# tests/unit/test_result_validator.py

import pytest
from postgres_mcp.core.result_validator import ResultValidator
from postgres_mcp.models.result import QueryResult, ColumnInfo
from postgres_mcp.models.validation import ValidationLevel, ValidationIssue


@pytest.mark.asyncio
async def test_empty_result_detection():
    """æµ‹è¯•ç©ºç»“æœæ£€æµ‹"""
    validator = ResultValidator()
    result = QueryResult(
        columns=[ColumnInfo(name="id", type="integer")],
        rows=[],
        row_count=0,
        execution_time_ms=10.0,
        sql="SELECT * FROM users WHERE false",
    )
    
    validation = await validator.validate(
        result=result,
        natural_language="show all users",
        level=ValidationLevel.BASIC,
    )
    
    assert not validation.valid
    assert ValidationIssue.EMPTY_RESULT in validation.issues
    assert len(validation.suggestions) > 0


@pytest.mark.asyncio
async def test_column_mismatch_detection():
    """æµ‹è¯•åˆ—åä¸åŒ¹é…æ£€æµ‹"""
    validator = ResultValidator()
    result = QueryResult(
        columns=[ColumnInfo(name="product_id", type="integer")],
        rows=[{"product_id": 1}],
        row_count=1,
        execution_time_ms=10.0,
        sql="SELECT product_id FROM products",
    )
    
    validation = await validator.validate(
        result=result,
        natural_language="show all users",  # è¯·æ±‚ users ä½†è¿”å› products
        level=ValidationLevel.BASIC,
    )
    
    assert ValidationIssue.COLUMN_MISMATCH in validation.issues


@pytest.mark.asyncio
async def test_too_many_rows_detection():
    """æµ‹è¯•ç»“æœè¿‡å¤šæ£€æµ‹"""
    validator = ResultValidator(max_expected_rows=100)
    result = QueryResult(
        columns=[ColumnInfo(name="id", type="integer")],
        rows=[{"id": i} for i in range(100)],
        row_count=100,
        execution_time_ms=50.0,
        truncated=True,
        sql="SELECT * FROM large_table",
    )
    
    validation = await validator.validate(
        result=result,
        natural_language="show all records",
        level=ValidationLevel.BASIC,
    )
    
    assert ValidationIssue.TOO_MANY_ROWS in validation.issues


@pytest.mark.asyncio
async def test_valid_result():
    """æµ‹è¯•æ­£å¸¸ç»“æœéªŒè¯é€šè¿‡"""
    validator = ResultValidator()
    result = QueryResult(
        columns=[ColumnInfo(name="user_id", type="integer")],
        rows=[{"user_id": 1}, {"user_id": 2}],
        row_count=2,
        execution_time_ms=10.0,
        sql="SELECT user_id FROM users",
    )
    
    validation = await validator.validate(
        result=result,
        natural_language="show user IDs",
        level=ValidationLevel.BASIC,
    )
    
    assert validation.valid
    assert len(validation.issues) == 0
```

---

### T080: å®ç°æ–‡ä»¶

- `src/postgres_mcp/models/validation.py` (æ–°å¢ - æ•°æ®æ¨¡å‹)
- `src/postgres_mcp/core/result_validator.py` (æ–°å¢ - éªŒè¯å™¨)
- `src/postgres_mcp/ai/openai_client.py` (ä¿®æ”¹ - æ·»åŠ éªŒè¯æ–¹æ³•)

### T081: é›†æˆåˆ° QueryExecutor

- `src/postgres_mcp/core/query_executor.py` (ä¿®æ”¹ - æ·»åŠ éªŒè¯è°ƒç”¨)
- `src/postgres_mcp/server.py` (ä¿®æ”¹ - åˆå§‹åŒ– validator)

---

## ğŸ“Š å®ç°å·¥ä½œé‡ä¼°ç®—

| ä»»åŠ¡ | æ–‡ä»¶ | å·¥ä½œé‡ | è¯´æ˜ |
|------|------|--------|------|
| **T079** | æ•°æ®æ¨¡å‹ | 0.5h | validation.py (5 ä¸ªç±») |
| **T079** | å•å…ƒæµ‹è¯• | 1h | test_result_validator.py (8-10 tests) |
| **T080** | ResultValidator | 2h | åŸºç¡€éªŒè¯ + AI éªŒè¯é€»è¾‘ |
| **T080** | OpenAI æ‰©å±• | 0.5h | validate_result_relevance æ–¹æ³• |
| **T081** | QueryExecutor é›†æˆ | 0.5h | æ·»åŠ å¯é€‰éªŒè¯è°ƒç”¨ |
| **T081** | é›†æˆæµ‹è¯• | 1h | ç«¯åˆ°ç«¯æµ‹è¯• |
| **ä»£ç å®¡æŸ¥** | - | 0.5h | Ruff, Mypy, æ–‡æ¡£ |
| **æ€»è®¡** | - | **6h** | çº¦ 1 ä¸ªå·¥ä½œæ—¥ |

---

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€éªŒè¯ (é»˜è®¤)

```python
# ä»…æœ¬åœ°æ£€æŸ¥ï¼Œæ—  AI è°ƒç”¨
executor = QueryExecutor(
    sql_generator=generator,
    pool_manager=pool_manager,
    query_runner=runner,
    result_validator=ResultValidator(),
    enable_validation=True,  # å¯ç”¨éªŒè¯
)

result = await executor.execute(
    natural_language="show all users",
    database="main_db",
)

# å¦‚æœç»“æœæœ‰é—®é¢˜ï¼Œerrors å­—æ®µåŒ…å«å»ºè®®
if result.errors:
    for error in result.errors:
        print(f"âš ï¸ {error}")
```

### AI è¯­ä¹‰éªŒè¯ (å¯é€‰)

```python
# å¯ç”¨ AI è¯­ä¹‰éªŒè¯
validator = ResultValidator(
    openai_client=openai_client,
    semantic_threshold=0.7,
)

executor = QueryExecutor(
    ...,
    result_validator=validator,
)

result = await executor.execute(
    natural_language="show active users",
    database="main_db",
    validate_result=True,  # æ˜¾å¼å¯ç”¨
)
```

---

## ğŸ”§ é…ç½®é€‰é¡¹

### config.yaml æ–°å¢é…ç½®

```yaml
# ç»“æœéªŒè¯é…ç½®
result_validation:
  enabled: false                    # é»˜è®¤å…³é—­ (å¯é€‰åŠŸèƒ½)
  level: "basic"                    # basic | semantic
  min_expected_rows: 1              # æœ€å°‘é¢„æœŸè¡Œæ•°
  max_expected_rows: 10000          # æœ€å¤§åˆç†è¡Œæ•°
  semantic_threshold: 0.7           # AI åŒ¹é…é˜ˆå€¼
  enable_ai_suggestions: false      # æ˜¯å¦å¯ç”¨ AI æ”¹è¿›å»ºè®®
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ€§èƒ½å½±å“**:
   - åŸºç¡€éªŒè¯: ~1-5ms é¢å¤–å¼€é”€ âœ… å¯æ¥å—
   - AI è¯­ä¹‰éªŒè¯: ~500-2000ms é¢å¤–å¼€é”€ âš ï¸ ä»…åœ¨éœ€è¦æ—¶å¯ç”¨

2. **æˆæœ¬å½±å“**:
   - AI éªŒè¯æ¯æ¬¡è°ƒç”¨æ¶ˆè€— ~200-500 tokens
   - å»ºè®®ä»…åœ¨è¿”å›ç©ºç»“æœæˆ–ç”¨æˆ·æ˜ç¡®è¯·æ±‚æ—¶å¯ç”¨

3. **é™çº§ç­–ç•¥**:
   - AI éªŒè¯å¤±è´¥æ—¶è‡ªåŠ¨é™çº§ä¸ºé€šè¿‡
   - ä¸é˜»æ­¢æ­£å¸¸æŸ¥è¯¢è¿”å›

4. **å¯é€‰æ€§**:
   - é»˜è®¤å…³é—­ï¼Œä¸å½±å“ç°æœ‰åŠŸèƒ½
   - ç”¨æˆ·å¯é€šè¿‡é…ç½®æˆ–å‚æ•°å¯ç”¨

---

## ğŸ¯ å®ç°ä¼˜å…ˆçº§å»ºè®®

### æ¨èå®ç°é¡ºåº

1. **é˜¶æ®µ 1: åŸºç¡€éªŒè¯** (T079, T080) - 3h
   - âœ… æ•°æ®æ¨¡å‹
   - âœ… ResultValidator (ä»… basic validation)
   - âœ… å•å…ƒæµ‹è¯•
   - ğŸ’¡ **æ”¶ç›Š**: ç«‹å³å¯ç”¨ï¼Œæ— é¢å¤–æˆæœ¬

2. **é˜¶æ®µ 2: QueryExecutor é›†æˆ** (T081) - 1h
   - âœ… é›†æˆåˆ°æŸ¥è¯¢æµç¨‹
   - âœ… é…ç½®é€‰é¡¹
   - ğŸ’¡ **æ”¶ç›Š**: ç«¯åˆ°ç«¯åŠŸèƒ½

3. **é˜¶æ®µ 3: AI è¯­ä¹‰éªŒè¯** (T080 æ‰©å±•) - 2h
   - ğŸ¤– OpenAI é›†æˆ
   - ğŸ¤– Semantic validation
   - ğŸ’¡ **æ”¶ç›Š**: é«˜çº§åŠŸèƒ½ï¼Œå¯é€‰å¯ç”¨

---

## ğŸ“ˆ ä»·å€¼è¯„ä¼°

| ç»´åº¦ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| **ç”¨æˆ·ä½“éªŒæå‡** | â­â­â­â­ | å‡å°‘å›°æƒ‘å’Œé‡å¤æŸ¥è¯¢ |
| **ç³»ç»Ÿæ™ºèƒ½åŒ–** | â­â­â­â­â­ | AI éªŒè¯å¢å¼ºå‡†ç¡®æ€§ |
| **å®ç°å¤æ‚åº¦** | â­â­â­ | ä¸­ç­‰ï¼Œçº¦ 6 å°æ—¶ |
| **ç»´æŠ¤æˆæœ¬** | â­â­ | ä½ï¼Œé€»è¾‘æ¸…æ™° |
| **MVP å¿…è¦æ€§** | â­ | éå¿…éœ€ï¼Œå¢å¼ºåŠŸèƒ½ |

**ç»“è®º**: å¦‚æœè¿½æ±‚æ›´æ™ºèƒ½çš„ç”¨æˆ·ä½“éªŒï¼Œå»ºè®®å®ç° **é˜¶æ®µ 1 + é˜¶æ®µ 2** (åŸºç¡€éªŒè¯ + é›†æˆ)ï¼Œçº¦ 4 å°æ—¶ã€‚AI è¯­ä¹‰éªŒè¯ (é˜¶æ®µ 3) å¯ä½œä¸ºæœªæ¥å¢å¼ºã€‚

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [spec.md - US5](../001-postgres-mcp/spec.md#ç”¨æˆ·æ•…äº‹-5)
- [tasks.md - T079-T081](../001-postgres-mcp/tasks.md)
- [plan.md](../001-postgres-mcp/plan.md)

---

**å‡†å¤‡å¥½å®ç°äº†å—ï¼Ÿ** å¦‚éœ€å¼€å§‹å®ç°ï¼Œæˆ‘å¯ä»¥ï¼š
1. åˆ›å»ºæ•°æ®æ¨¡å‹ (`validation.py`)
2. å®ç° `ResultValidator` (åŸºç¡€éªŒè¯)
3. ç¼–å†™å•å…ƒæµ‹è¯•
4. é›†æˆåˆ° `QueryExecutor`
